{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12850488,"sourceType":"datasetVersion","datasetId":7940313},{"sourceId":573239,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":422148,"modelId":439732}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"ac7b684f","cell_type":"markdown","source":"# ***Hierarchical BiLSTM***","metadata":{}},{"id":"b0e5f3a1","cell_type":"markdown","source":"## Import Required Libraries","metadata":{}},{"id":"9a4fbc43-a25f-4737-b121-aab4f658a126","cell_type":"code","source":"!pip install rouge_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T02:47:14.779439Z","iopub.execute_input":"2025-09-10T02:47:14.779601Z","iopub.status.idle":"2025-09-10T02:47:20.865779Z","shell.execute_reply.started":"2025-09-10T02:47:14.779585Z","shell.execute_reply":"2025-09-10T02:47:20.864882Z"}},"outputs":[{"name":"stdout","text":"Collecting rouge_score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge_score) (3.9.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.26.4)\nRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.17.0)\nRequirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (8.2.1)\nRequirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (1.5.1)\nRequirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (2024.11.6)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (4.67.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rouge_score) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rouge_score) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->rouge_score) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->rouge_score) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->rouge_score) (2024.2.0)\nBuilding wheels for collected packages: rouge_score\n  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=9826cb7c7564b35b9c1558c22f2234b4941b754d02384013d0cb085713fc0ad0\n  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\nSuccessfully built rouge_score\nInstalling collected packages: rouge_score\nSuccessfully installed rouge_score-0.1.2\n","output_type":"stream"}],"execution_count":1},{"id":"e4a9a660","cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, Subset\nimport torch.nn.functional as F\nfrom torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\nfrom gensim.models import Word2Vec\nfrom tqdm import tqdm\nimport re\nfrom rouge_score import rouge_scorer\nimport matplotlib.pyplot as plt\nimport gc\nfrom collections import Counter\nimport traceback","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T02:47:20.869663Z","iopub.execute_input":"2025-09-10T02:47:20.869917Z","iopub.status.idle":"2025-09-10T02:47:59.820349Z","shell.execute_reply.started":"2025-09-10T02:47:20.869885Z","shell.execute_reply":"2025-09-10T02:47:59.819737Z"}},"outputs":[],"execution_count":2},{"id":"923ad9bb","cell_type":"markdown","source":"## Load Processed Data","metadata":{}},{"id":"221f8343","cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/text-summarization/train.csv')\nvalid_df = pd.read_csv('/kaggle/input/text-summarization/valid.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T02:47:59.821587Z","iopub.execute_input":"2025-09-10T02:47:59.822023Z","iopub.status.idle":"2025-09-10T02:48:32.387366Z","shell.execute_reply.started":"2025-09-10T02:47:59.822003Z","shell.execute_reply":"2025-09-10T02:48:32.386753Z"}},"outputs":[],"execution_count":3},{"id":"8b99347d","cell_type":"code","source":"def doc_to_sentences(doc: str) -> list:\n    parts = re.split(r'\\s([.!?:])(?:\\s+|$)', doc.strip())\n    parts = [part for part in parts if part]\n    sentences = []\n    buffer = ''\n    for part in parts:\n        if part.strip() in '.!?\"\\'':\n            buffer += ' ' + part.strip()\n        else:\n            if buffer:\n                sentences.append(buffer)\n            buffer = part.strip()\n    if buffer:\n        sentences.append(buffer.strip())\n    return sentences\n\ndoc_test = 'Tổng bí thư Nguyễn Phú Trọng phát biểu lúc 12h49 ngày 1/1/2990 . \" Quốc hội khai. mạc phiên họp thứ 2 ! \" . '\nprint(doc_to_sentences(doc_test))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"68f3593c","cell_type":"code","source":"docs = train_df['content'].apply(doc_to_sentences).tolist()\ndoc_lengths = [len(doc) for doc in docs]\nsent_lengths = [len(sent.split()) for doc in docs for sent in doc]\nsummary_lengths = [len(summary.split()) for summary in train_df['summary']]\n\nfig, axes = plt.subplots(1, 3, figsize=(18, 4))\nfig.suptitle('Train data distribution')\n\naxes[0].hist(doc_lengths, bins=50, color='green')\naxes[0].set_title('Doc Lengths')\naxes[0].set_xlabel('Number of sentences')\naxes[0].set_ylabel('Frequency')\n\naxes[1].hist(sent_lengths, bins=50, color='orange')\naxes[1].set_title('Sentence Lengths')\naxes[1].set_xlabel('Number of words')\naxes[1].set_ylabel('Frequency')\n\naxes[2].hist(summary_lengths, bins=50, color='blue')\naxes[2].set_title('Summary Lengths')\naxes[2].set_xlabel('Number of words')\naxes[2].set_ylabel('Frequency')\n\nplt.tight_layout(rect=[0, 0, 1, 0.95])\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"15c44922","cell_type":"markdown","source":"## Load Word2Vec","metadata":{}},{"id":"1dac9309","cell_type":"code","source":"class Vocab:\n    def __init__(self, word2vec_model_path: str):\n        self.model = Word2Vec.load(word2vec_model_path)\n        \n        self.word2id = {}\n        self.id2word = {}\n        self.embedding_dim = self.model.vector_size\n        self.build()\n        self.unk_id = self.word2id['<UNK>']\n        self.pad_id = self.word2id['<PAD>']\n        self.sos_id = self.word2id['<SOS>']\n        self.eos_id = self.word2id['<EOS>']\n        self.num_id = self.get_index('<NUM>')\n        self.time_id = self.get_index('<TIME>')\n        self.date_id = self.get_index('<DATE>')\n        self.num_regexp = r\"[\\d.,]*\\d[\\d.,]*\"\n        self.time_regexp = r\"(\\d{1,2}h(\\d{1,2})?)\"\n        self.date_regexp = r\"(\\d{1,2}/\\d{1,2}(/\\d{2,4})?)\"\n\n    def build(self):\n        id = 0\n        for word in self.model.wv.index_to_key:\n            self.word2id[word] = id\n            self.id2word[id] = word\n            id += 1\n        special_tokens = ['<UNK>', '<PAD>', '<SOS>', '<EOS>']\n        for token in special_tokens:\n            self.word2id[token] = id\n            self.id2word[id] = token\n            id += 1\n    \n    def __len__(self):\n        return len(self.word2id)\n    \n    def get_index(self, word):\n        return self.word2id.get(word, self.unk_id)\n    \n    def get_word(self, id):\n        return self.id2word.get(id, '<UNK>')\n\n    def decode(self, ids, oov):\n        ids = [id for id in ids if id not in [self.unk_id, self.pad_id, self.eos_id, self.sos_id, self.num_id, self.time_id, self.date_id]]\n        words = []\n        len_vocab = self.__len__()\n        for id in ids:\n            if id >= len_vocab + len(oov):\n                continue\n            elif id >= len_vocab:\n                words.append(oov[id - len_vocab])\n            else:\n                words.append(self.get_word(id))\n        return ' '.join(words)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T02:48:32.388095Z","iopub.execute_input":"2025-09-10T02:48:32.388414Z","iopub.status.idle":"2025-09-10T02:48:32.396823Z","shell.execute_reply.started":"2025-09-10T02:48:32.388361Z","shell.execute_reply":"2025-09-10T02:48:32.396050Z"}},"outputs":[],"execution_count":4},{"id":"289c928f","cell_type":"code","source":"vocab = Vocab('/kaggle/input/text-summarization/word2vec_skipgram.model')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T02:48:32.397532Z","iopub.execute_input":"2025-09-10T02:48:32.397762Z","iopub.status.idle":"2025-09-10T02:48:34.376144Z","shell.execute_reply.started":"2025-09-10T02:48:32.397739Z","shell.execute_reply":"2025-09-10T02:48:34.375580Z"}},"outputs":[],"execution_count":5},{"id":"c681c224-3a8e-4912-839e-bc47e55aeb9b","cell_type":"code","source":"print(len(vocab))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"5b5243d9-9477-4d95-82b9-11a2980e493b","cell_type":"code","source":"vocab.model.wv.most_similar(\"tốt\", topn=10)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"01981d64","cell_type":"markdown","source":"## Create Dataset and Loader","metadata":{}},{"id":"bcaf1261","cell_type":"code","source":"class SummarizationDataset(Dataset):\n    def __init__(\n        self, \n        df: pd.DataFrame, \n        max_doc_length: int, \n        max_sentence_length:int, \n        max_summary_length: int, \n        vocab: Vocab\n    ):\n        self.max_doc_length = max_doc_length\n        self.max_sentence_length = max_sentence_length\n        self.max_summary_length = max_summary_length\n        self.vocab = vocab\n        self.data = []\n        for row in df.itertuples(index=False):\n            input, extend_input, oov = self.encode_content(row.content)\n            target, extend_target = self.encode_summary(row.summary, oov)\n            if len(input) == 0 or len(target) == 0:\n                continue\n            self.data.append((input, extend_input, target, extend_target, oov))\n\n    def encode_content(self, content):\n        parts = re.split(r'\\s([.!?:])(?:\\s+|$)', content.strip())\n        parts = [part for part in parts if part]\n        sentences = []\n        buffer = ''\n        for part in parts:\n            if part.strip() in '.!?\"\\'':\n                buffer += ' ' + part.strip()\n            else:\n                if buffer:\n                    sentences.append(buffer)\n                buffer = part.strip()\n        if buffer:\n            sentences.append(buffer.strip())\n        tokens = [sentence.split() for sentence in sentences]\n        if len(tokens) > self.max_doc_length:\n            tokens = tokens[:self.max_doc_length]\n        origin = []\n        extend = []\n        oov = []\n        for sentence in tokens:\n            origin_sent = []\n            extend_sent = []\n            if len(sentence) > self.max_sentence_length:\n                sentence = sentence[:self.max_sentence_length]\n            for word in sentence:\n                id = self.vocab.get_index(word)\n                if id == self.vocab.unk_id:\n                    if re.fullmatch(self.vocab.num_regexp, word):\n                        id = self.vocab.num_id\n                    elif re.fullmatch(self.vocab.time_regexp, word):\n                        id = self.vocab.time_id\n                    elif re.fullmatch(self.vocab.date_regexp, word):\n                        id = self.vocab.date_id\n                    origin_sent.append(id)\n                    if word not in oov:\n                        oov.append(word)\n                    extend_sent.append(len(self.vocab) + oov.index(word))\n                else:\n                    origin_sent.append(id)\n                    extend_sent.append(id)\n            origin.append(origin_sent)\n            extend.append(extend_sent)\n        return origin, extend, oov\n    \n    def encode_summary(self, summary, oov):\n        sentence = summary.strip().split()\n        if len(sentence) + 2 > self.max_summary_length:\n            sentence = sentence[:self.max_summary_length - 2]\n        origin = []\n        extend = []\n        for word in sentence:\n            id = self.vocab.get_index(word)\n            if id == self.vocab.unk_id:\n                if re.fullmatch(self.vocab.num_regexp, word):\n                    id = self.vocab.num_id\n                elif re.fullmatch(self.vocab.time_regexp, word):\n                    id = self.vocab.time_id\n                elif re.fullmatch(self.vocab.date_regexp, word):\n                    id = self.vocab.date_id\n            origin.append(id)\n            if word in oov:\n                extend.append(len(self.vocab) + oov.index(word))\n            else: \n                extend.append(id)\n        return origin, extend\n\n    def __len__(self):\n        return len(self.data)\n    \n    def pad_content(self, doc):\n        padded = []\n        if len(doc) > self.max_doc_length:\n            doc = doc[:self.max_doc_length]\n        for sentence in doc:\n            if len(sentence) < self.max_sentence_length:\n                sentence += [self.vocab.pad_id] * (self.max_sentence_length - len(sentence))\n            elif len(sentence) > self.max_sentence_length:\n                sentence = sentence[:self.max_sentence_length]\n            padded.append(sentence)\n        if len(padded) < self.max_doc_length:\n            padded += [[self.vocab.pad_id] * self.max_sentence_length] * (self.max_doc_length - len(padded))\n        \n        return padded\n    def pad_summary(self, doc):\n        if len(doc) > self.max_summary_length:\n            doc = doc[:self.max_summary_length]\n        else:\n            doc += [self.vocab.pad_id] * (self.max_summary_length - len(doc))\n        \n        return doc\n\n    def __getitem__(self, index):\n        input, extend_input, target, extend_target, oov = self.data[index]\n        target = [self.vocab.sos_id] + target + [self.vocab.eos_id]\n        extend_target = [self.vocab.sos_id] + extend_target + [self.vocab.eos_id]\n        input = self.pad_content(input)\n        attention_mask = [[1 if token != self.vocab.pad_id else 0 for token in sent] for sent in input]\n        extend_input = self.pad_content(extend_input)\n        target = self.pad_summary(target)\n        extend_target = self.pad_summary(extend_target)\n        \n        return {\n            'input': torch.tensor(input, dtype=torch.long),\n            'attention_mask': torch.tensor(attention_mask, dtype=torch.long),\n            'extend_input': torch.tensor(extend_input, dtype=torch.long),\n            'target': torch.tensor(target, dtype=torch.long),\n            'extend_target': torch.tensor(extend_target, dtype=torch.long),\n            'oov': oov\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T02:48:34.376755Z","iopub.execute_input":"2025-09-10T02:48:34.376934Z","iopub.status.idle":"2025-09-10T02:48:34.393922Z","shell.execute_reply.started":"2025-09-10T02:48:34.376919Z","shell.execute_reply":"2025-09-10T02:48:34.393407Z"}},"outputs":[],"execution_count":6},{"id":"5047c9ce-7128-4b53-87b7-4383bd571c3f","cell_type":"code","source":"class DatasetChunk(Dataset):\n    def __init__(self, dataset, indices):\n        self.dataset = dataset\n        self.indices = indices\n\n    def __len__(self):\n        return len(self.indices)\n\n    def __getitem__(self, idx):\n        real_idx = self.indices[idx]\n        return self.dataset[real_idx]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T02:48:34.396059Z","iopub.execute_input":"2025-09-10T02:48:34.396324Z","iopub.status.idle":"2025-09-10T02:48:34.438291Z","shell.execute_reply.started":"2025-09-10T02:48:34.396306Z","shell.execute_reply":"2025-09-10T02:48:34.437624Z"}},"outputs":[],"execution_count":7},{"id":"12d2f59b","cell_type":"code","source":"def collate_fn(batch):\n    input_ids = torch.stack([item['input'] for item in batch])\n    attention_mask = torch.stack([item['attention_mask'] for item in batch])\n    extend_input_ids = torch.stack([item['extend_input'] for item in batch])\n    target_ids = torch.stack([item['target'] for item in batch])\n    extend_target_ids = torch.stack([item['extend_target'] for item in batch])\n    oov_lists = [item['oov'] for item in batch]\n\n    return {\n        'input_ids': input_ids,\n        'attention_mask': attention_mask,\n        'extend_input_ids': extend_input_ids,\n        'target_ids': target_ids,\n        'extend_target_ids': extend_target_ids,\n        'oov_lists': oov_lists\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T02:48:34.438976Z","iopub.execute_input":"2025-09-10T02:48:34.439215Z","iopub.status.idle":"2025-09-10T02:48:34.453952Z","shell.execute_reply.started":"2025-09-10T02:48:34.439198Z","shell.execute_reply":"2025-09-10T02:48:34.453256Z"}},"outputs":[],"execution_count":8},{"id":"97625cb8-5145-490a-9347-d7a9465cbf20","cell_type":"code","source":"max_doc_length = 45\nmax_sent_length = 60\nmax_summary_length = 60","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T02:48:34.454766Z","iopub.execute_input":"2025-09-10T02:48:34.455448Z","iopub.status.idle":"2025-09-10T02:48:34.469924Z","shell.execute_reply.started":"2025-09-10T02:48:34.455425Z","shell.execute_reply":"2025-09-10T02:48:34.469246Z"}},"outputs":[],"execution_count":9},{"id":"11d725f4","cell_type":"code","source":"train_dataset = SummarizationDataset(\n    df=train_df, \n    max_doc_length= max_doc_length, \n    max_sentence_length=max_sent_length, \n    max_summary_length=max_summary_length, \n    vocab=vocab\n)\nvalid_dataset = SummarizationDataset(\n    df=valid_df, \n    max_doc_length= max_doc_length, \n    max_sentence_length=max_sent_length, \n    max_summary_length=max_summary_length, \n    vocab=vocab\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T02:48:34.470776Z","iopub.execute_input":"2025-09-10T02:48:34.471240Z","iopub.status.idle":"2025-09-10T02:50:28.712731Z","shell.execute_reply.started":"2025-09-10T02:48:34.471217Z","shell.execute_reply":"2025-09-10T02:50:28.711952Z"}},"outputs":[],"execution_count":10},{"id":"2d832f46-070e-4321-a3f5-f7823659481e","cell_type":"code","source":"def create_dataloaders(dataset, n_chunks, batch_size=16, collate_fn=collate_fn):\n    length = len(dataset)\n    indices = np.random.permutation(length)\n    chunk_size = length // n_chunks\n\n    dataloaders = []\n    for i in range(n_chunks):\n        start_idx = i * chunk_size\n        end_idx = (i + 1) * chunk_size if i < n_chunks - 1 else length\n        chunk_indices = indices[start_idx:end_idx]\n\n        chunk_dataset = DatasetChunk(dataset, chunk_indices)\n        dl = DataLoader(\n            chunk_dataset,\n            batch_size=batch_size,\n            shuffle=True,\n            pin_memory=True,\n            num_workers=4,\n            collate_fn=collate_fn\n        )\n        dataloaders.append(dl)\n    return dataloaders","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T02:50:28.713549Z","iopub.execute_input":"2025-09-10T02:50:28.713796Z","iopub.status.idle":"2025-09-10T02:50:28.718938Z","shell.execute_reply.started":"2025-09-10T02:50:28.713775Z","shell.execute_reply":"2025-09-10T02:50:28.718403Z"}},"outputs":[],"execution_count":11},{"id":"474888a8-6bad-4a50-a6bb-3788c5bc8074","cell_type":"code","source":"train_loaders = create_dataloaders(train_dataset, n_chunks=4, batch_size=16)\nvalid_loader = DataLoader(valid_dataset, batch_size=128, pin_memory=True, shuffle=False, num_workers=4, collate_fn=collate_fn)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T02:50:28.719657Z","iopub.execute_input":"2025-09-10T02:50:28.719870Z","iopub.status.idle":"2025-09-10T02:50:28.745412Z","shell.execute_reply.started":"2025-09-10T02:50:28.719849Z","shell.execute_reply":"2025-09-10T02:50:28.744709Z"}},"outputs":[],"execution_count":12},{"id":"9dc5ac65","cell_type":"markdown","source":"## Define Model","metadata":{}},{"id":"c3e21e3d-d22e-4b1c-b7a2-45663703f3aa","cell_type":"code","source":"class Word2VecEmbedding(nn.Module):\n    def __init__(self, vocab: Vocab):\n        super().__init__()\n        self.vocab = vocab\n        self.embedding = nn.Embedding(len(vocab), vocab.embedding_dim)\n        self.adapter = nn.Linear(vocab.embedding_dim, vocab.embedding_dim)\n        self.load_pretrained_weights()\n    \n    def load_pretrained_weights(self):\n        self.embedding.weight.requires_grad = False\n        weights = []\n        for i in range(len(self.vocab)):\n            word = self.vocab.get_word(i)\n            if word in self.vocab.model.wv:\n                vec = self.vocab.model.wv[word]\n            else:\n                vec = np.random.normal(scale=0.1, size=self.vocab.embedding_dim)\n            weights.append(torch.tensor(vec, dtype=torch.float32))\n        weights[self.vocab.pad_id] = torch.zeros(self.vocab.embedding_dim)\n        \n        weights_tensor = torch.stack(weights)\n        with torch.no_grad():\n            self.embedding.weight.copy_(weights_tensor)\n    \n    def forward(self, x):\n        x = self.embedding(x)\n        x = self.adapter(x)\n        x = F.gelu(x)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T02:50:28.746207Z","iopub.execute_input":"2025-09-10T02:50:28.746414Z","iopub.status.idle":"2025-09-10T02:50:28.752889Z","shell.execute_reply.started":"2025-09-10T02:50:28.746399Z","shell.execute_reply":"2025-09-10T02:50:28.752406Z"}},"outputs":[],"execution_count":13},{"id":"7f45dc59-d586-4f18-a66a-f44fccb60f72","cell_type":"code","source":"class AttentionPooling(nn.Module):\n    def __init__(\n        self,\n        hidden_dim,\n        # dropout\n    ):\n        super().__init__()\n        self.adapter = nn.Linear(hidden_dim, hidden_dim)\n        self.norm = nn.LayerNorm(hidden_dim)\n        self.score_mlp = nn.Sequential(\n            nn.Linear(hidden_dim, hidden_dim//2),\n            nn.GELU(),\n            nn.Linear(hidden_dim//2, 1)\n        )\n        nn.init.constant_(self.score_mlp[-1].bias, 0.1)\n        self.temperature = nn.Parameter(torch.tensor(1.0))\n        # self.dropout = nn.Dropout(dropout)\n        \n    def forward(self, hiddens, mask=None):\n        h = self.adapter(hiddens)\n        h = F.relu(h)\n        h = self.norm(h)\n        \n        # [..., H] -> [..., 1] -> [...]\n        scores = self.score_mlp(h).squeeze(-1) / self.temperature\n\n        if mask is not None:\n            scores = scores.masked_fill(mask == 0, -1e4)\n\n        # [...] -> [..., 1]\n        weights = F.softmax(scores, dim=-1).unsqueeze(-1)\n\n        context = torch.sum(h * weights, dim=-2)\n\n        return context + 0.1 * hiddens.mean(dim=-2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T02:50:28.753482Z","iopub.execute_input":"2025-09-10T02:50:28.753640Z","iopub.status.idle":"2025-09-10T02:50:28.769025Z","shell.execute_reply.started":"2025-09-10T02:50:28.753626Z","shell.execute_reply":"2025-09-10T02:50:28.768315Z"}},"outputs":[],"execution_count":14},{"id":"a2396d4d-624d-41e4-8d1d-d91e826908ac","cell_type":"code","source":"class ResidualBlock(nn.Module):\n    def __init__(\n        self,\n        input_dim,\n        hidden_dim,\n        # dropout=0.3,\n        activation=nn.ReLU,\n    ):\n        super().__init__()\n        self.norm = nn.LayerNorm(input_dim)\n        self.fc1 = nn.Linear(input_dim, hidden_dim)\n        self.fc2 = nn.Linear(hidden_dim, input_dim)\n        # self.dropout = nn.Dropout(dropout)\n        self.activation = activation()\n\n    def forward(self, x):\n        x = self.norm(x)\n        out = self.fc1(x)\n        out = self.activation(out)\n\n        out = self.fc2(out)\n        return self.activation(x + out)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T02:50:28.769820Z","iopub.execute_input":"2025-09-10T02:50:28.770047Z","iopub.status.idle":"2025-09-10T02:50:28.788424Z","shell.execute_reply.started":"2025-09-10T02:50:28.770023Z","shell.execute_reply":"2025-09-10T02:50:28.787822Z"}},"outputs":[],"execution_count":15},{"id":"c7a6f9ca-961b-4a8a-bc1a-5ad81489c28f","cell_type":"code","source":"class Encoder(nn.Module):\n    def __init__(\n        self,\n        embedding_dim,\n        hidden_size_word, \n        word_residual_configs,\n        hidden_size_sent,\n        sent_residual_configs,\n        dropout=0.3,\n    ):\n        super().__init__()\n        self.embedding_dim = embedding_dim\n        self.hidden_size_word = hidden_size_word\n        self.hidden_size_sent = hidden_size_sent\n        self.dropout = nn.Dropout(dropout)\n\n        self.word_input_norm = nn.LayerNorm(embedding_dim)\n        \n        # Word-level BiLSTM\n        self.word_layer = nn.LSTM(\n            input_size=self.embedding_dim,\n            hidden_size=self.hidden_size_word,\n            bidirectional=True,\n            batch_first=True\n        )\n\n        self.word_attention_pooling = AttentionPooling(\n            2 * self.hidden_size_word, \n            # dropout\n        )\n\n        self.word_residuals = nn.Sequential(\n            *[\n                ResidualBlock(\n                    input_dim=2 * hidden_size_word,\n                    hidden_dim=config['hidden_dim'],\n                    # dropout=dropout,\n                    activation=config['activation']\n                )\n                for config in word_residual_configs\n            ]\n        )\n\n        self.sent_input_norm = nn.LayerNorm(2 * hidden_size_word)\n        \n        # Sentence-level BiLSTM\n        self.sent_layer = nn.LSTM(\n            input_size=self.hidden_size_word * 2,\n            hidden_size=self.hidden_size_sent,\n            bidirectional=True,\n            batch_first=True\n        )\n\n        self.sent_attention_pooling = AttentionPooling(\n            2 * self.hidden_size_sent, \n            # dropout\n        )\n        \n        self.sent_residuals = nn.Sequential(\n            *[\n                ResidualBlock(\n                    input_dim=2 * self.hidden_size_sent,\n                    hidden_dim=config['hidden_dim'],\n                    # dropout=dropout,\n                    activation=config['activation']\n                )\n                for config in sent_residual_configs\n            ]\n        )\n        \n    def forward(self, embedded_inputs, attention_masks, debug=False):\n        \"\"\"\n        B: Batch size\n        S: Number of sentences\n        W: Number of words in a sentences\n        D: Embedding dim\n        HW: Hidden word size\n        HS: Hidden sent size\n\n        Args:\n            embedded_inputs: [B, S, W, D]\n            attention_mask: [B, S, W]\n        Returns:\n            output: [B, 2HS]\n            word_layer_outputs: [B, S * W, 2HW]\n        \"\"\"\n\n        B, S, W = attention_masks.shape\n        device = embedded_inputs.device\n\n        # Flatten \n        # [B, S, W, D] -> [B * S, W, D]\n        flatted_inputs = embedded_inputs.view(B * S, W, -1)\n        flatted_inputs = self.word_input_norm(flatted_inputs)\n        flatted_inputs = self.dropout(flatted_inputs)\n\n        # [B, S, W] -> [B * S, W]\n        flatted_masks = attention_masks.view(B * S, -1)\n\n        # === Word-level BiLSTM ===\n        \n        # Compute lengths for packing\n        sent_lengths = flatted_masks.sum(dim=1).cpu()\n        valid_masks = sent_lengths > 0\n\n        packed_word_layer_inputs = pack_padded_sequence(\n            flatted_inputs[valid_masks],\n            lengths=sent_lengths[valid_masks],\n            batch_first=True,\n            enforce_sorted=False\n        )\n        packed_word_layer_outputs, _ = self.word_layer(packed_word_layer_inputs)\n        \n        # [B_valid, W, 2HW]\n        unpacked_word_layer_outputs, _ = pad_packed_sequence(packed_word_layer_outputs, batch_first=True, total_length=W)\n\n        # [B * S, W, 2HW]\n        word_layer_outputs = torch.zeros(B * S, W, 2 * self.hidden_size_word, device=device)\n        word_layer_outputs[valid_masks] = unpacked_word_layer_outputs\n\n        # [B * S, W, 2HW] -> [B * S, 2HW]\n        sent_layer_inputs = self.word_attention_pooling(word_layer_outputs, flatted_masks)\n        sent_layer_inputs = self.dropout(sent_layer_inputs)\n        \n        sent_layer_inputs = self.word_residuals(sent_layer_inputs)\n\n        # [B * S, 2HW] -> [B, S, 2HW]\n        sent_layer_inputs = sent_layer_inputs.view(B, S, -1)\n        sent_layer_inputs = self.sent_input_norm(sent_layer_inputs)\n        sent_layer_inputs = self.dropout(sent_layer_inputs)\n\n        # === Sentence-level BiLSTM ===\n\n        # Compute lengths for packing\n        doc_masks = (attention_masks.sum(dim=2) > 0).long()\n        doc_lengths = doc_masks.sum(dim=-1).cpu()\n\n        packed_sent_layer_inputs = pack_padded_sequence(\n            sent_layer_inputs,\n            lengths=doc_lengths,\n            batch_first=True,\n            enforce_sorted=False\n        )\n        packed_sent_layer_outputs, _ = self.sent_layer(packed_sent_layer_inputs)\n\n        sent_layer_outputs, _ = pad_packed_sequence(packed_sent_layer_outputs, batch_first=True, total_length=S)\n\n        # [B, S, 2HS] -> [B, 2HS]\n        outputs = self.sent_attention_pooling(sent_layer_outputs)\n        outputs = self.dropout(outputs)\n        \n        outputs = self.sent_residuals(outputs)\n        \n        return outputs, word_layer_outputs.view(B, S * W, -1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T02:50:28.789049Z","iopub.execute_input":"2025-09-10T02:50:28.789241Z","iopub.status.idle":"2025-09-10T02:50:28.804691Z","shell.execute_reply.started":"2025-09-10T02:50:28.789226Z","shell.execute_reply":"2025-09-10T02:50:28.804084Z"}},"outputs":[],"execution_count":16},{"id":"970e2350-b218-4c44-b2f8-545a77d3629b","cell_type":"code","source":"class Attention(nn.Module):\n    def __init__(\n        self,\n        hidden_size_word,\n        hidden_size_decoder,\n        attention_dim,\n        dropout\n    ):\n        super().__init__()\n        self.enc_proj = nn.Linear(hidden_size_word * 2, attention_dim)\n        self.enc_norm = nn.LayerNorm(attention_dim)\n        self.dec_proj = nn.Linear(hidden_size_decoder, attention_dim, bias=False)\n        self.dec_norm = nn.LayerNorm(attention_dim)\n        self.score_proj = nn.Linear(attention_dim, 1)\n        self.dropout = nn.Dropout(dropout)\n        nn.init.constant_(self.score_proj.bias, 0.1)\n    \n    def forward(self, dec_hidden, enc_outputs, enc_proj=None, enc_mask=None):\n        \"\"\"\n        Args:\n            dec_hidden: [B, 1, H]\n            enc_outputs: [B, S * W, 2HW]\n            enc_proj: [B, S * W, A]\n            enc_mask: [B, S * W]\n        Returns:\n            context: [B, 2HW]\n        \"\"\"\n        B, SxW, _ = enc_outputs.size()\n\n        if enc_proj is None:\n            # [B, S * W, 2HW] -> [B, S * W, A]\n            enc_proj = self.enc_proj(enc_outputs)\n            enc_proj = self.enc_norm(enc_proj)\n\n        # [B, 1, H] -> [B, 1, A]\n        dec_proj = self.dec_proj(dec_hidden)\n        dec_proj = self.dec_norm(dec_proj)\n\n        attn_features = F.gelu(enc_proj + dec_proj)\n        attn_features = self.dropout(attn_features)\n\n        # [B, S * W, A] -> [B, S * W, 1] -> [B, S * W]\n        attn_scores = self.score_proj(attn_features).squeeze(-1)\n\n        if enc_mask is not None:\n            attn_scores = attn_scores.masked_fill(enc_mask == 0, float('-inf'))\n\n        attn_weights = F.softmax(attn_scores, dim=-1)\n\n        # [B, 1, S * W] @ [B, S * W, 2HW] -> [B, 1, 2HW] -> [B, 2HW]\n        context = torch.bmm(attn_weights.unsqueeze(1), enc_outputs).squeeze(1)\n\n        return context, attn_weights","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T02:50:28.805643Z","iopub.execute_input":"2025-09-10T02:50:28.805874Z","iopub.status.idle":"2025-09-10T02:50:28.825342Z","shell.execute_reply.started":"2025-09-10T02:50:28.805854Z","shell.execute_reply":"2025-09-10T02:50:28.824665Z"}},"outputs":[],"execution_count":17},{"id":"12220d53-4743-4942-b6c0-9781db6bef15","cell_type":"code","source":"class PointerGenerator(nn.Module):\n    def __init__(\n        self, \n        hidden_size_decoder, \n        hidden_size_word, \n        embedding_dim\n    ):\n        super().__init__()\n        self.ptr_proj = nn.Linear(hidden_size_decoder + 2 * hidden_size_word + embedding_dim, 1)\n\n    def forward(self, context, emb_input, vocab_dist, attn_weights, ext_input_ids, ext_vocab_size):\n        \"\"\"\n        Args:\n            context: [B, 2HW + H]\n            embedded_input: [B, D]\n            vocab_dist: [B, V]\n            attn_weights: [B, S * W]\n            ext_input_ids: [B]\n            ext_vocab_size: int\n        Returns:\n            final_dist: [B, EV]\n        \"\"\"\n        B, V = vocab_dist.size()\n        device = context.device\n\n        # [B, 2HW + H] cat [B, D] -> [B, 2HW + H + D]\n        ptr_input = torch.cat([context, emb_input], dim=-1)\n\n        # [B, 2HW + H + D] -> [B, 1]\n        ptr_gate = torch.sigmoid(self.ptr_proj(ptr_input))\n\n        # [B, 1] * [B, V] -> [B, V]\n        vocab_dist_scaled = ptr_gate * vocab_dist\n\n        # [B, 1] * [B, S * W] -> [B, S * W]\n        attn_dist_scaled = (1 - ptr_gate) * attn_weights\n\n        final_dist = torch.zeros(B, ext_vocab_size, device=device)\n        final_dist[:, :vocab_dist.size(-1)] += vocab_dist_scaled\n        final_dist.scatter_add_(1, ext_input_ids.long(), attn_dist_scaled)\n\n        return final_dist","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T02:50:28.825895Z","iopub.execute_input":"2025-09-10T02:50:28.826088Z","iopub.status.idle":"2025-09-10T02:50:28.844123Z","shell.execute_reply.started":"2025-09-10T02:50:28.826064Z","shell.execute_reply":"2025-09-10T02:50:28.843415Z"}},"outputs":[],"execution_count":18},{"id":"d71a5bd9-4b4f-4524-8804-a2bd79fe2c7d","cell_type":"code","source":"class Decoder(nn.Module):\n    def __init__(\n        self, \n        embedding_dim, \n        embedding_matrix,   \n        hidden_size, \n        vocab_size,\n        hidden_size_word, \n        residual_configs,\n        attn_dim=256, \n        dropout=0.3\n    ):\n        super().__init__()\n        self.hidden_size = hidden_size\n        self.embedding_dim = embedding_dim\n        self.vocab_size = vocab_size\n        self.hidden_size_word=hidden_size_word\n        self.embedding_matrix = embedding_matrix\n\n        self.dropout = nn.Dropout(dropout)\n        \n        # === Attention ===\n\n        # Project encoder word_outputs\n        self.attention = Attention(\n            hidden_size_word=hidden_size_word,\n            hidden_size_decoder=hidden_size,\n            attention_dim=attn_dim,\n            dropout=dropout\n        )\n\n        self.lstm_input_norm = nn.LayerNorm(embedding_dim + 2 * hidden_size_word)\n\n        # === Decoder LSTM ===\n        self.dec_lstm = nn.LSTM(\n            input_size=self.embedding_dim + 2 * hidden_size_word,\n            hidden_size=hidden_size,\n            batch_first=True\n        )\n\n        self.residuals = nn.Sequential(\n            *[\n                ResidualBlock(\n                    input_dim=hidden_size,\n                    hidden_dim=config['hidden_dim'],\n                    # dropout=dropout,\n                    activation=config['activation']\n                )\n                for config in residual_configs\n            ]\n        )\n\n        # === Vocab projection ===\n        self.contextual_dec_out_norm = nn.LayerNorm(hidden_size + 2 * hidden_size_word)\n        self.emb_proj = nn.Linear(hidden_size + 2 * hidden_size_word, self.embedding_dim)\n        \n        # === Pointer-generator gate ===\n        self.ptr_gen = PointerGenerator(\n            hidden_size_decoder=self.hidden_size,\n            hidden_size_word=self.hidden_size_word,\n            embedding_dim=self.embedding_dim\n        )\n        \n    def forward(\n        self, \n        embedded_input, \n        decoder_state, \n        encoder_word_outputs, \n        ext_input_ids, \n        ext_vocab_size, \n        encoder_mask=None,\n        debug=False,\n        enc_proj=None\n    ):\n        \"\"\"\n        B: Batch size\n        S: Number of sentences\n        W: Number of words in a sentences\n        D: Embedding dim\n        HW: Hidden word size\n        HS: Hidden sent size\n        H: Hidden decoder size\n        A: Attention dim\n        V: Vocab size\n        EV: Extended vocab size\n        \n        Args:\n            embedded_input: [B, D]\n            decoder_state: ([1, B, H], [1, B, H])\n            encoder_word_outputs: [B, S * W, 2HW]\n            ext_input_ids: [B, S * W]\n            ext_vocab_size: int\n        Returns:\n            final_dist: [B, EV]\n            next_decoder_state: ([1, B, H], [1, B, H])\n        \"\"\"\n        B, SxW, _ = encoder_word_outputs.size()\n\n        # === Embedding input token ===\n        \n        # [B, D] -> [B, 1, D]\n        embedded_input = embedded_input.unsqueeze(1)\n\n        # === Attention ===\n        # [1, B, H] -> [B, 1, H]\n        dec_hidden = decoder_state[0].transpose(0, 1)\n\n        # [B, 2HW], [B, S * W]\n        context, attn_weights = self.attention(dec_hidden, encoder_word_outputs, enc_proj, encoder_mask)\n\n        # [B, 2HW] -> [B, 1, 2HW]\n        context = context.unsqueeze(1)\n\n        # === Decoder LSTM ===\n        \n        # [B, 1, D] cat [B, 1, 2HW] -> [B, 1, D + 2HW]\n        lstm_input = torch.cat([embedded_input, context], dim=-1)\n        lstm_input = self.lstm_input_norm(lstm_input)\n        lstm_input = self.dropout(lstm_input)\n\n        lstm_out, next_decoder_state = self.dec_lstm(lstm_input, decoder_state)\n        lstm_out = self.residuals(lstm_out)\n\n        # === Vocab distribution ===\n        \n        # [B, 1, H] cat [B, 1, 2HW] -> [B, 1, H + 2HW]\n        contextual_dec_out = torch.cat([lstm_out, context], dim=-1)\n        contextual_dec_out = self.contextual_dec_out_norm(contextual_dec_out)\n        contextual_dec_out = self.dropout(contextual_dec_out)\n\n        # [B, 1, H + 2HW] -> [B, 1, D] -> [B, D]\n        emb_out = self.emb_proj(contextual_dec_out).squeeze(1)\n        \n        # [B, D] x [D, V] -> [B, V]\n        vocab_logits = torch.matmul(emb_out, self.embedding_matrix.T)\n        vocab_dist = F.softmax(vocab_logits, dim=-1)\n\n        # === Pointer generator ===\n\n        # [B, 1, H + 2HW] -> [B, H + 2HW]\n        contextual_dec_out = contextual_dec_out.squeeze(1)\n\n        # [B, 1, D] -> [B, D]\n        embedded_input = embedded_input.squeeze(1)\n        \n        final_dist = self.ptr_gen(contextual_dec_out, embedded_input, vocab_dist, attn_weights, ext_input_ids, ext_vocab_size)\n\n        return final_dist, next_decoder_state","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T02:50:28.846542Z","iopub.execute_input":"2025-09-10T02:50:28.846897Z","iopub.status.idle":"2025-09-10T02:50:28.864707Z","shell.execute_reply.started":"2025-09-10T02:50:28.846873Z","shell.execute_reply":"2025-09-10T02:50:28.864160Z"}},"outputs":[],"execution_count":19},{"id":"ee82660b-63d1-4caa-903f-643116b6e947","cell_type":"code","source":"class Model(nn.Module):\n    def __init__(\n            self,\n            vocab: Vocab,\n            enc_hidden_size_word,\n            enc_word_residual_configs,\n            enc_hidden_size_sent,\n            enc_sent_residual_configs,\n            dec_hidden_size,\n            dec_residual_configs,\n            dec_attn_dim,\n            device: torch.device,\n            dropout=0.3\n    ):\n        super().__init__()\n        self.vocab = vocab\n\n        # === Embedding ===\n        self.embedding_layer = Word2VecEmbedding(vocab)\n\n        # === Encoder ===\n        self.encoder = Encoder(\n            embedding_dim=vocab.embedding_dim,\n            hidden_size_word=enc_hidden_size_word,\n            word_residual_configs=enc_word_residual_configs,\n            hidden_size_sent=enc_hidden_size_sent,\n            sent_residual_configs=enc_sent_residual_configs,\n            dropout=dropout\n        )\n\n        # === Adapter ===\n        self.dropout = nn.Dropout(dropout)\n        self.adapter = nn.Linear(2 * enc_hidden_size_sent, dec_hidden_size)\n\n        # === Decoder ===\n        self.decoder = Decoder(\n            embedding_dim=vocab.embedding_dim,\n            embedding_matrix=self.embedding_layer.embedding.weight,\n            hidden_size=dec_hidden_size,\n            vocab_size=len(vocab),\n            hidden_size_word=enc_hidden_size_word,\n            residual_configs=dec_residual_configs,\n            attn_dim=dec_attn_dim,\n            dropout=dropout\n        )\n        \n        self.to(device)\n    \n    def forward(\n        self, \n        input_ids, \n        ext_input_ids, \n        target_ids, \n        attention_mask, \n        teacher_forcing_ratio=0.5, \n        debug=False\n    ):\n        \"\"\"\n        B: Batch size\n        S: Number of sentences\n        W: Number of words in a sentences\n        D: Embedding dim\n        HW: Hidden word size\n        HS: Hidden sent size\n        H: Hidden decoder size\n        A: Attention dim\n        V: Vocab size\n        EV: Extended vocab size\n        L: Target length\n        \n        Args:\n            input_ids: [B, S, W]\n            ext_input_ids: [B, S, W]\n            target_ids: [B, L]\n            attention_mask: [B, S, W]\n        Returns:\n            final_dists: [B, L, EV]\n        \"\"\"\n        B, T = target_ids.size()\n        pad_id = self.vocab.pad_id\n        \n        target_mask = target_ids != pad_id\n        max_len = target_mask.sum(dim=1).max().item()\n\n        # === Encode ===\n\n        # [B, S, W] -> [B, S, W, D]\n        enc_embedded_input = self.embedding_layer(input_ids)\n        \n        # [B, 2HS], [B, S * W, 2HW]\n        sent_hidden, word_outputs = self.encoder(enc_embedded_input, attention_mask, debug=debug)\n\n        # Precompute encoder attention projection\n\n        # [B, S * W, 2HW] -> [B, S * W, A]\n        enc_proj = self.decoder.attention.enc_proj(word_outputs)\n        enc_proj = self.decoder.attention.enc_norm(enc_proj)\n        \n        # === Init decoder state ===\n        \n        # [B]\n        decoder_input = torch.full((B,), self.vocab.sos_id, dtype=torch.long, device=input_ids.device)\n        \n        # [B] -> [B, D]\n        decoder_embedded_input = self.embedding_layer(decoder_input)\n        \n        # [B, 2HS] -> [B, H] -> [1, B, H]\n        h = self.adapter(sent_hidden).unsqueeze(0)\n        h = F.relu(h)\n        h = self.dropout(h)\n        c = torch.zeros_like(h)\n        \n        decoder_state = (h, c)\n        \n        # [B, S, W] -> [B, S * W]\n        input_ids = input_ids.view(B, -1)\n        ext_input_ids = ext_input_ids.view(B, -1)\n\n        # [B, S, W] -> [B, S * W]\n        encoder_mask = attention_mask.view(B, -1)\n\n        ext_vocab_size = ext_input_ids.max().item() + 1\n\n        # === Decode ===\n        final_dists = torch.zeros(B, T, ext_vocab_size, device=input_ids.device, dtype=torch.float32)\n        for t in range(max_len):\n\n            # [B, EV], ([1, B, H], [1, B, H])\n            final_dist, decoder_state = self.decoder(\n                decoder_embedded_input, \n                decoder_state, \n                word_outputs,\n                ext_input_ids, \n                ext_vocab_size,\n                encoder_mask=encoder_mask,\n                debug=debug and (t % 20 == 0),\n                enc_proj=enc_proj\n            )\n\n            final_dists[:, t, :] = final_dist\n\n            if torch.rand(1).item() < teacher_forcing_ratio:\n                decoder_input = target_ids[:, t]\n                decoder_embedded_input = self.embedding_layer(decoder_input)\n            else:\n                decoder_input = final_dist.argmax(1)\n                oov_mask = decoder_input >= len(self.vocab)\n                if oov_mask.any():\n                    oov_tokens = decoder_input[oov_mask]\n                    token_pos = (ext_input_ids[oov_mask] == oov_tokens.unsqueeze(1)).float().argmax(dim=1)\n                    copied_token = input_ids[oov_mask, token_pos]\n                    decoder_input[oov_mask] = copied_token\n                decoder_embedded_input = self.embedding_layer(decoder_input)\n\n        return final_dists","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T02:50:28.865556Z","iopub.execute_input":"2025-09-10T02:50:28.865808Z","iopub.status.idle":"2025-09-10T02:50:28.884763Z","shell.execute_reply.started":"2025-09-10T02:50:28.865787Z","shell.execute_reply":"2025-09-10T02:50:28.884183Z"}},"outputs":[],"execution_count":20},{"id":"bd525a63","cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = Model(\n    vocab=vocab,\n    enc_hidden_size_word=192,\n    enc_word_residual_configs=[\n        {'hidden_dim': 768, 'activation': nn.GELU},\n    ],\n    enc_hidden_size_sent=384,\n    enc_sent_residual_configs=[\n        {'hidden_dim': 1536, 'activation': nn.GELU},\n        # {'hidden_dim': 1536, 'activation': nn.GELU},\n    ],\n    dec_hidden_size=512,\n    dec_residual_configs=[\n        {'hidden_dim': 2048, 'activation': nn.GELU},  \n        {'hidden_dim': 1024, 'activation': nn.GELU},  \n        # {'hidden_dim': 2048, 'activation': nn.ReLU},  \n    ],\n    dec_attn_dim=256,\n    device=device,\n    dropout=0.25\n)\noptimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T02:50:28.885500Z","iopub.execute_input":"2025-09-10T02:50:28.885689Z","iopub.status.idle":"2025-09-10T02:50:33.320689Z","shell.execute_reply.started":"2025-09-10T02:50:28.885673Z","shell.execute_reply":"2025-09-10T02:50:33.320079Z"}},"outputs":[],"execution_count":21},{"id":"6a3ec7ee-d766-4ce7-8b2a-dfe488ed363e","cell_type":"code","source":"# del model\n# del optimizer\n# del scheduler\ntorch.cuda.empty_cache()\ngc.collect()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"4bebc2fc-b4ae-408a-a567-244f6de6c1bf","cell_type":"code","source":"def count_params(model):\n    encoder_params_count = sum(p.numel() for p in model.encoder.parameters() if p.requires_grad)\n    decoder_params_count = sum(p.numel() for p in model.decoder.parameters() if p.requires_grad)\n    model_params_count = sum(p.numel() for p in model.parameters() if p.requires_grad)\n\n    print(f'Encoder: {encoder_params_count}')\n    print(f'Decoder: {decoder_params_count}')\n    print(f'Model: {model_params_count}')\n\ncount_params(model)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"0d9f82f2-9c27-48e9-b734-4e90d8a96559","cell_type":"code","source":"def print_gradients(model, max_elements=500):\n    for name, param in model.named_parameters():\n        if param.grad is None:\n            print(f\"{name}: No gradient\")\n        else:\n            grad = param.grad.detach().cpu().numpy()\n            num_elements = grad.size\n            if num_elements <= max_elements:\n                print(f\"{name} grad (shape={grad.shape}):\\n{grad}\\n\")\n            else:\n                print(\n                    f\"{name} grad (shape={grad.shape}, elements={num_elements}) \"\n                    f\"min={grad.min():.6f}, max={grad.max():.6f}, mean={grad.mean():.6f}\"\n                )\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"2cb24017-0d6e-4325-9d70-d35412124093","cell_type":"code","source":"print_gradients(model, max_elements=100)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"e60f0ee7","cell_type":"markdown","source":"## Train","metadata":{}},{"id":"36bfe05a-e947-4104-8178-918df0fe547f","cell_type":"code","source":"def get_tfr(epoch):\n    k = 10\n    return k / (k + np.exp(epoch / k))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T02:50:33.321422Z","iopub.execute_input":"2025-09-10T02:50:33.321808Z","iopub.status.idle":"2025-09-10T02:50:33.325203Z","shell.execute_reply.started":"2025-09-10T02:50:33.321789Z","shell.execute_reply":"2025-09-10T02:50:33.324505Z"}},"outputs":[],"execution_count":22},{"id":"137132f8-7fca-4192-b25b-95dfbd78f383","cell_type":"code","source":"def train_one_epoch(\n    model,\n    dataloaders,\n    optimizer,\n    device,\n    teacher_forcing_ratio=0.5,\n):\n    model.train()\n    total_loss = 0\n    step = 0\n    for dl in dataloaders:\n        for batch in tqdm(dl, desc='Train'):\n            try:\n                input_ids = batch['input_ids'].to(device)\n                attention_mask = batch['attention_mask'].to(device)\n                extend_input_ids = batch['extend_input_ids'].to(device)\n                target_ids = batch['target_ids'].to(device)\n                extend_target_ids = batch['extend_target_ids'].to(device)\n                # oov_lists = batch['oov_lists']\n\n                optimizer.zero_grad()\n\n                outputs = model(\n                    input_ids,\n                    extend_input_ids,\n                    target_ids,\n                    attention_mask,\n                    # oov_lists,\n                    teacher_forcing_ratio,\n                    # debug=step%100==0\n                )   # [B, T, EV]\n\n                B, T, EV = outputs.shape\n                outputs = outputs.view(B * T, EV)\n                targets = extend_target_ids.view(-1)\n\n                mask = targets != model.vocab.pad_id\n                \n                picked_probs = outputs[torch.arange(B * T), targets]\n                picked_probs = picked_probs[mask]\n                log_probs = - torch.log(picked_probs + 1e-12)\n                loss = log_probs.mean()\n\n                loss.backward()\n                nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n\n                optimizer.step()\n\n                total_loss += loss.item()\n                step += 1\n                # if step % 100 == 0:\n                #     print(total_loss / step)\n            except Exception as e:\n                torch.cuda.empty_cache()\n                print(e)\n                traceback.print_exc()\n        torch.cuda.empty_cache()\n        gc.collect()\n        print(f'Train loss: {total_loss / step}')\n\n    return total_loss / sum([len(dl) for dl in dataloaders])\n\ndef evaluate(model, dataloader, device):\n    model.eval()\n    scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n    total_score = 0\n    total_sample = 0\n    max_len = 100\n    pad_id = model.vocab.pad_id\n    sos_id = model.vocab.sos_id\n    eos_id = model.vocab.eos_id\n\n    with torch.no_grad():\n        for batch in tqdm(dataloader, desc='Validate'):\n            try:\n                input_ids = batch['input_ids'].to(device)\n                attention_mask = batch['attention_mask'].to(device)\n                extend_input_ids = batch['extend_input_ids'].to(device)\n                target_ids = batch['target_ids'].to(device)\n                extend_target_ids = batch['extend_target_ids'].to(device)\n                oov_lists = batch['oov_lists']\n\n                B, T = target_ids.size()\n\n                enc_embedded_input = model.embedding_layer(input_ids)\n            \n                sent_hidden, word_outputs = model.encoder(enc_embedded_input, attention_mask)\n\n                enc_proj = model.decoder.attention.enc_proj(word_outputs)\n                enc_proj = model.decoder.attention.enc_norm(enc_proj)\n        \n                h = model.adapter(sent_hidden).unsqueeze(0)\n                h = F.relu(h)\n                c = torch.zeros_like(h)\n                decoder_state = (h, c)\n\n                input_ids = input_ids.view(B, -1)\n                ext_input_ids = extend_input_ids.view(B, -1)\n\n                encoder_mask = attention_mask.view(B, -1)\n\n                ext_vocab_size = ext_input_ids.max().item() + 1\n\n                seqs = torch.full((B, max_len), sos_id, dtype=torch.long, device=device)\n                decoder_embedded_input = model.embedding_layer(seqs[:, 0])\n                active_mask = torch.full((B,), True, dtype=torch.bool, device=device)\n                for t in range(max_len):\n                    if not active_mask.any():\n                        break\n        \n                    # [B, EV], ([1, B, H], [1, B, H])\n                    final_dist, decoder_state = model.decoder(\n                        decoder_embedded_input, \n                        decoder_state, \n                        word_outputs,\n                        ext_input_ids, \n                        ext_vocab_size,\n                        encoder_mask=encoder_mask,\n                        # debug=debug and (t % 20 == 0),\n                        enc_proj=enc_proj\n                    )\n        \n                    decoder_input = final_dist.argmax(1)\n                    seqs[active_mask, t] = decoder_input\n\n                    next_active = decoder_input != eos_id\n                    temp_active_mask = active_mask.clone()\n                    temp_active_mask[active_mask] = next_active\n                    active_mask = temp_active_mask\n                    decoder_input = decoder_input[next_active]\n                    decoder_state = decoder_state[0][:, next_active], decoder_state[1][:, next_active]\n                    word_outputs = word_outputs[next_active]\n                    ext_input_ids = ext_input_ids[next_active]\n                    encoder_mask = encoder_mask[next_active]\n                    enc_proj = enc_proj[next_active]\n                                        \n                    oov_mask = decoder_input >= len(model.vocab)\n                    if oov_mask.any():\n                        oov_tokens = decoder_input[oov_mask]\n                        token_pos = (ext_input_ids[oov_mask] == oov_tokens.unsqueeze(1)).float().argmax(dim=1)\n                        copied_token = input_ids[active_mask][oov_mask, token_pos]\n                        decoder_input[oov_mask] = copied_token\n                    decoder_embedded_input = model.embedding_layer(decoder_input)\n    \n                seqs = seqs.tolist()\n                for pred_seq, tgt_seq, oov_list in zip(seqs, extend_target_ids.tolist(), oov_lists):\n                    pred_text = model.vocab.decode(pred_seq, oov_list)\n                    tgt_text = model.vocab.decode(tgt_seq, oov_list)\n                    rougeL = scorer.score(tgt_text, pred_text)['rougeL'].fmeasure\n                    total_score += rougeL\n                total_sample += B\n\n            except Exception as e:\n                torch.cuda.empty_cache()\n                print(e)\n                traceback.print_exc()\n\n    rougeL_F1 = total_score / total_sample\n    return rougeL_F1\n\ndef train_model(\n    model, \n    train_loaders, \n    valid_loader, \n    optimizer,\n    # scheduler, \n    device, \n    num_epochs,\n    checkpoint_path=None\n):\n    history=[]\n    best_score=float('-inf')\n    best_epoch = 0\n    \n    if checkpoint_path:\n        checkpoint = torch.load(checkpoint_path)\n        model.load_state_dict(checkpoint['model_state_dict'])\n        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n        history = checkpoint['history']\n        for epoch_summary in history:\n            print(f'Epoch {epoch_summary[0]}:')\n            print(f'\\tTrain Loss: {epoch_summary[1]}')\n            print(f'\\tValid RougeL F1 Score: {epoch_summary[2]}')\n            print('-' * 50)\n        best_entry = max(history, key=lambda x: x[2])\n        best_epoch, _, best_score = best_entry\n    \n    start_epoch = len(history) + 1\n    counter = start_epoch - best_epoch - 1\n    for epoch in range(start_epoch, start_epoch + num_epochs):\n        print(f\"Epoch {epoch}\\n\")\n        tfr = get_tfr(epoch)\n        train_loss = train_one_epoch(model, train_loaders, optimizer, device, tfr)\n        torch.cuda.empty_cache()\n        gc.collect()\n        \n        valid_score = evaluate(model, valid_loader, device)\n        \n        print(f\"\\nTrain Loss: {train_loss:.4f}\")\n        print(f\"Valid RougeL F1 Score: {valid_score:.4f}\")\n        \n        torch.cuda.empty_cache()\n        gc.collect()\n\n        history.append([epoch, train_loss, valid_score])\n        train_loaders = create_dataloaders(train_dataset, n_chunks=4, batch_size=16)\n\n        print('-' * 50)\n        torch.save({\n            'model_state_dict': model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'history': history\n        },f'last_model.pt')\n        if valid_score > best_score:\n            best_score = valid_score\n            best_epoch = epoch\n            counter = 0\n            lr = optimizer.param_groups[0]['lr']\n            torch.save({\n                'model_state_dict': model.state_dict(),\n                'optimizer_state_dict': optimizer.state_dict(),\n                'history': history\n            },f'best_model.pt')\n        else:\n            counter += 1\n            if counter >= 5:\n                print(f\"\\nEarly stop\")\n                print(f\"Best model with rougeL F1 score {best_score:.4f}\")\n                breakđây\n        torch.cuda.empty_cache()\n        gc.collect()\n    return history","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T02:50:33.326045Z","iopub.execute_input":"2025-09-10T02:50:33.326292Z","iopub.status.idle":"2025-09-10T02:50:33.352947Z","shell.execute_reply.started":"2025-09-10T02:50:33.326269Z","shell.execute_reply":"2025-09-10T02:50:33.352267Z"}},"outputs":[],"execution_count":23},{"id":"501a78f2-2987-4351-94e6-ff69bdb73f8a","cell_type":"code","source":"history = train_model(\n    model=model,\n    train_loaders=train_loaders,\n    valid_loader=valid_loader,\n    optimizer=optimizer,   \n    device=device,\n    num_epochs=4,\n    checkpoint_path='/kaggle/input/temp_sum_cl1/keras/default/4/last_model (2).pt'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T02:50:33.353694Z","iopub.execute_input":"2025-09-10T02:50:33.354290Z","iopub.status.idle":"2025-09-10T13:16:58.221037Z","shell.execute_reply.started":"2025-09-10T02:50:33.354267Z","shell.execute_reply":"2025-09-10T13:16:58.220190Z"}},"outputs":[{"name":"stdout","text":"Epoch 1:\n\tTrain Loss: 4.023476720182794\n\tValid RougeL F1 Score: 0.3212430272957445\n--------------------------------------------------\nEpoch 2:\n\tTrain Loss: 3.485653291535287\n\tValid RougeL F1 Score: 0.3349350829569631\n--------------------------------------------------\nEpoch 3:\n\tTrain Loss: 3.3265960655958904\n\tValid RougeL F1 Score: 0.3423784768101486\n--------------------------------------------------\nEpoch 4:\n\tTrain Loss: 3.2439604321588105\n\tValid RougeL F1 Score: 0.3453295379966757\n--------------------------------------------------\nEpoch 5:\n\tTrain Loss: 3.1962489743700924\n\tValid RougeL F1 Score: 0.350088586728179\n--------------------------------------------------\nEpoch 6:\n\tTrain Loss: 3.167288500675912\n\tValid RougeL F1 Score: 0.34979728399091703\n--------------------------------------------------\nEpoch 7:\n\tTrain Loss: 3.151025692734897\n\tValid RougeL F1 Score: 0.3522262259552\n--------------------------------------------------\nEpoch 8:\n\tTrain Loss: 3.1489390870827036\n\tValid RougeL F1 Score: 0.35357867829853185\n--------------------------------------------------\nEpoch 9:\n\tTrain Loss: 3.1506643952684867\n\tValid RougeL F1 Score: 0.35612577497858117\n--------------------------------------------------\nEpoch 10:\n\tTrain Loss: 3.158362546024371\n\tValid RougeL F1 Score: 0.35550102670522404\n--------------------------------------------------\nEpoch 11:\n\tTrain Loss: 3.1776756148297123\n\tValid RougeL F1 Score: 0.35496691154283033\n--------------------------------------------------\nEpoch 12:\n\tTrain Loss: 3.2004388752261947\n\tValid RougeL F1 Score: 0.35666547849152597\n--------------------------------------------------\nEpoch 13:\n\tTrain Loss: 3.2239384193913723\n\tValid RougeL F1 Score: 0.35717028911404\n--------------------------------------------------\nEpoch 14:\n\tTrain Loss: 3.259347813426067\n\tValid RougeL F1 Score: 0.3569985534024202\n--------------------------------------------------\nEpoch 15:\n\tTrain Loss: 3.295281311554392\n\tValid RougeL F1 Score: 0.35780873489689374\n--------------------------------------------------\nEpoch 16:\n\tTrain Loss: 3.3366867533299773\n\tValid RougeL F1 Score: 0.3570044772377301\n--------------------------------------------------\nEpoch 17\n\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 4746/4746 [37:23<00:00,  2.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train loss: 3.365365261123294\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 4746/4746 [37:17<00:00,  2.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train loss: 3.3697469319616045\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 4746/4746 [37:22<00:00,  2.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train loss: 3.373250090015924\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 4746/4746 [37:22<00:00,  2.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train loss: 3.3774940278074985\n","output_type":"stream"},{"name":"stderr","text":"Validate: 100%|██████████| 524/524 [06:22<00:00,  1.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 3.3775\nValid RougeL F1 Score: 0.3563\n--------------------------------------------------\nEpoch 18\n\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 4746/4746 [37:20<00:00,  2.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train loss: 3.4085345110007093\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 4746/4746 [37:24<00:00,  2.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train loss: 3.4181075974878157\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 4746/4746 [37:28<00:00,  2.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train loss: 3.4198784989693776\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 4746/4746 [37:26<00:00,  2.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train loss: 3.422079115308542\n","output_type":"stream"},{"name":"stderr","text":"Validate: 100%|██████████| 524/524 [06:19<00:00,  1.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 3.4221\nValid RougeL F1 Score: 0.3590\n--------------------------------------------------\nEpoch 19\n\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 4746/4746 [37:27<00:00,  2.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train loss: 3.4608597342745946\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 4746/4746 [37:15<00:00,  2.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train loss: 3.464447443451602\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 4746/4746 [37:18<00:00,  2.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train loss: 3.4645791653000013\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 4746/4746 [37:19<00:00,  2.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train loss: 3.469405723689379\n","output_type":"stream"},{"name":"stderr","text":"Validate: 100%|██████████| 524/524 [06:16<00:00,  1.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 3.4694\nValid RougeL F1 Score: 0.3565\n--------------------------------------------------\nEpoch 20\n\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 4746/4746 [37:24<00:00,  2.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train loss: 3.5051844111987926\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 4746/4746 [37:21<00:00,  2.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train loss: 3.5117353535230986\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 4746/4746 [37:21<00:00,  2.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train loss: 3.5157973740204347\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 4746/4746 [37:19<00:00,  2.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train loss: 3.5197370967631896\n","output_type":"stream"},{"name":"stderr","text":"Validate: 100%|██████████| 524/524 [06:19<00:00,  1.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 3.5197\nValid RougeL F1 Score: 0.3526\n--------------------------------------------------\n","output_type":"stream"}],"execution_count":24},{"id":"45ca43b4","cell_type":"markdown","source":"## Test","metadata":{}},{"id":"f4bce89f-f138-4bb4-bb7d-31235662106c","cell_type":"code","source":"def generate(model, input_ids, ext_input_ids, attention_mask, oov_lists, max_len=100, beam_size=5):\n    \"\"\"\n    input_ids: [B, S, W]\n    extend_input_ids: [B, S, W]\n    attention_mask: [B, S, W]\n    oov_lists: [B, []]\n    \"\"\"\n\n    model.eval()\n    B, S, W = input_ids.shape\n    sos_id = model.vocab.sos_id\n    eos_id = model.vocab.eos_id\n    vocab_size = len(model.vocab)\n    device = input_ids.device\n    \n    with torch.no_grad():\n\n        enc_embedded_input = model.embedding_layer(input_ids)\n        \n        sent_hidden, word_outputs = model.encoder(enc_embedded_input, attention_mask)\n        \n        enc_proj = model.decoder.attention.enc_proj(word_outputs)\n        enc_proj = model.decoder.attention.enc_norm(enc_proj)\n                    \n        h = model.adapter(sent_hidden).unsqueeze(0)\n        h = F.relu(h)\n        h = h.repeat_interleave(beam_size, dim=1)\n        c = torch.zeros_like(h)\n        decoder_state = (h, c)\n        \n        input_ids = input_ids.view(B, -1)\n        ext_input_ids = ext_input_ids.view(B, -1)\n        encoder_mask = attention_mask.view(B, -1)\n        ext_vocab_size = ext_input_ids.max().item() + 1\n\n        word_outputs  = word_outputs.repeat_interleave(beam_size, dim=0)   # [B*beam_size, S*W, 2HW]\n        enc_proj = enc_proj.repeat_interleave(beam_size, dim=0)       # [B*beam_size, S*W, A]\n        encoder_mask  = encoder_mask.repeat_interleave(beam_size, dim=0)   # [B*beam_size, S*W]\n        ext_input_ids = ext_input_ids.repeat_interleave(beam_size, dim=0)  # [B*beam_size, S*W]\n        input_ids = input_ids.repeat_interleave(beam_size, dim=0)\n        \n        # seqs: [B * beam-size, n]\n        # log_probs: [B * beam-size]\n        seqs = torch.full((B * beam_size, 1), sos_id, dtype=torch.long, device=input_ids.device)\n        log_probs = torch.zeros(B * beam_size, device=input_ids.device)\n        decoder_embedded_input = model.embedding_layer(seqs[:, -1])\n        # List({'seq', 'log_prob'})\n        finished = [[] for _ in range(B)]\n\n        for _ in range(max_len):\n\n            # [B * beam_size, EV], ([1, B * beam-size, H], [1, B * beam-size, H])\n            final_dist, decoder_state = model.decoder(\n                decoder_embedded_input, \n                decoder_state, \n                word_outputs,\n                ext_input_ids, \n                ext_vocab_size,\n                encoder_mask=encoder_mask,\n                enc_proj=enc_proj\n            )\n\n            log_prob = final_dist.log()\n\n            # [B, beam-size, EV]\n            log_prob = log_prob.view(B, beam_size, -1)\n\n            # [B, beam-size, EV]\n            total_log_probs = log_probs.view(B, beam_size, 1) + log_prob\n            \n            # [B, beam-size * EV]\n            total_log_probs = total_log_probs.view(B, -1)\n\n            # [B, beam-size]\n            topk_log_probs, topk_ids = total_log_probs.topk(beam_size, dim=-1)\n            beam_indices = topk_ids // ext_vocab_size\n            token_indices = topk_ids % ext_vocab_size\n\n            flat_beam_indices = (beam_indices + (torch.arange(B, device=device) * beam_size).unsqueeze(1)).view(-1)\n\n            old_seqs = seqs[flat_beam_indices]\n            new_tokens = token_indices.view(-1, 1)\n            seqs = torch.cat([old_seqs, new_tokens], dim=1)\n\n            decoder_input = seqs[:, -1]\n            oov_mask = decoder_input >= vocab_size\n            if oov_mask.any():\n                oov_tokens = decoder_input[oov_mask]\n                token_pos = (ext_input_ids[oov_mask] == oov_tokens.unsqueeze(1)).float().argmax(dim=1)\n                copied_token = input_ids[oov_mask, token_pos]\n                decoder_input[oov_mask] = copied_token\n            decoder_embedded_input = model.embedding_layer(decoder_input)\n\n            new_h = decoder_state[0].index_select(1, flat_beam_indices)\n            new_c = decoder_state[1].index_select(1, flat_beam_indices)\n            decoder_state = (new_h, new_c)\n\n            log_probs = topk_log_probs.view(-1)\n            eos_mask = (token_indices == eos_id)\n            if eos_mask.any():\n                # [[b, k], ...]\n                eos_indices = eos_mask.nonzero(as_tuple=False)\n                flat_eos_indices = eos_indices[:, 0] * beam_size + eos_indices[:, 1]\n\n                eos_scores = log_probs[flat_eos_indices]\n                eos_seqs = seqs[flat_eos_indices]\n\n                for (b, k), score, seq in zip(eos_indices.tolist(), eos_scores.tolist(), eos_seqs):\n                    finished[b].append({\n                        'seq': seq.tolist(),\n                        'log_prob': score / (((5 + len(seq)) / 6) ** 0.6)\n                    })\n                log_probs[flat_eos_indices] = -1e9\n            all_enough = all(len(finished[b]) >= beam_size for b in range(B))\n            if all_enough:\n                break\n        \n        results = []\n        for b in range(B):\n            if finished[b]:\n                best_seq = max(finished[b], key=lambda x: x['log_prob'])['seq']\n            else:\n                best_seq = seqs[b * beam_size].tolist()\n            best_seq = best_seq[1:]\n            if eos_id in best_seq:\n                id = best_seq.index(eos_id)\n                best_seq = best_seq[:id]\n            results.append(best_seq)\n        return results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T13:17:05.227660Z","iopub.execute_input":"2025-09-10T13:17:05.227947Z","iopub.status.idle":"2025-09-10T13:17:05.242889Z","shell.execute_reply.started":"2025-09-10T13:17:05.227922Z","shell.execute_reply":"2025-09-10T13:17:05.242296Z"}},"outputs":[],"execution_count":25},{"id":"2dfc0f85","cell_type":"code","source":"def test(model, test_loader):\n    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=False)\n\n    all_metrics = {\n        'rouge1': {'precision': [], 'recall': [], 'f1': []},\n        'rouge2': {'precision': [], 'recall': [], 'f1': []},\n        'rougeL': {'precision': [], 'recall': [], 'f1': []},\n    }\n    \n    model.eval()\n    with torch.no_grad():\n        for batch in tqdm(test_loader, desc='Evaluate on test set'):\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            extend_input_ids = batch['extend_input_ids'].to(device)\n            target_ids = batch['target_ids'].to(device)\n            extend_target_ids = batch['extend_target_ids'].to(device)\n            oov_lists = batch['oov_lists']\n\n            outputs = generate(model, input_ids, extend_input_ids, attention_mask, oov_lists)\n            for pred, tgt, oov in zip(outputs, extend_target_ids.tolist(), oov_lists):\n                pred_seq = model.vocab.decode(pred, oov)\n                tgt_seq = model.vocab.decode(tgt, oov)\n\n                scores = scorer.score(tgt_seq, pred_seq)\n                for key in all_metrics:\n                    all_metrics[key]['precision'].append(scores[key].precision)\n                    all_metrics[key]['recall'].append(scores[key].recall)\n                    all_metrics[key]['f1'].append(scores[key].fmeasure)\n        \n    avg_metrics = {}\n    for key in all_metrics:\n        avg_metrics[key] = {\n            'precision': sum(all_metrics[key]['precision']) / len(all_metrics[key]['precision']),\n            'recall': sum(all_metrics[key]['recall']) / len(all_metrics[key]['recall']),\n            'f1': sum(all_metrics[key]['f1']) / len(all_metrics[key]['f1']),\n        }\n\n    return avg_metrics","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T13:17:09.426117Z","iopub.execute_input":"2025-09-10T13:17:09.426529Z","iopub.status.idle":"2025-09-10T13:17:09.434653Z","shell.execute_reply.started":"2025-09-10T13:17:09.426505Z","shell.execute_reply":"2025-09-10T13:17:09.434043Z"}},"outputs":[],"execution_count":26},{"id":"7f89253c-6051-4efd-b4fa-83a816663206","cell_type":"code","source":"test_df = pd.read_csv('/kaggle/input/text-summarization/test.csv')\ntest_dataset = SummarizationDataset(\n    df=test_df, \n    max_doc_length= max_doc_length, \n    max_sentence_length=max_sent_length, \n    max_summary_length=max_summary_length, \n    vocab=vocab\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T13:17:18.670351Z","iopub.execute_input":"2025-09-10T13:17:18.670612Z","iopub.status.idle":"2025-09-10T13:17:41.653224Z","shell.execute_reply.started":"2025-09-10T13:17:18.670594Z","shell.execute_reply":"2025-09-10T13:17:41.652637Z"}},"outputs":[],"execution_count":27},{"id":"3ccdda90-8ebd-4b83-b3bb-9aa61831ae93","cell_type":"code","source":"test_loader = DataLoader(test_dataset, batch_size=64, pin_memory=True, num_workers=4, collate_fn=collate_fn)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T13:17:41.654296Z","iopub.execute_input":"2025-09-10T13:17:41.654500Z","iopub.status.idle":"2025-09-10T13:17:41.658431Z","shell.execute_reply.started":"2025-09-10T13:17:41.654483Z","shell.execute_reply":"2025-09-10T13:17:41.657843Z"}},"outputs":[],"execution_count":28},{"id":"1ed6c9e6-3b3c-4626-8205-8439c3e01e22","cell_type":"code","source":"checkpoint = torch.load('/kaggle/working/best_model.pt')\n\nmodel.load_state_dict(checkpoint['model_state_dict'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T13:17:41.659184Z","iopub.execute_input":"2025-09-10T13:17:41.659365Z","iopub.status.idle":"2025-09-10T13:17:41.908021Z","shell.execute_reply.started":"2025-09-10T13:17:41.659352Z","shell.execute_reply":"2025-09-10T13:17:41.907293Z"}},"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}],"execution_count":29},{"id":"cef9ad1d","cell_type":"code","source":"scores = test(model, test_loader)\nfor k, v in scores.items():\n    print(f\"{k}: Precision={v['precision']:.4f}, Recall={v['recall']:.4f}, F1={v['f1']:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T13:17:41.909546Z","iopub.execute_input":"2025-09-10T13:17:41.909782Z","iopub.status.idle":"2025-09-10T13:40:41.803299Z","shell.execute_reply.started":"2025-09-10T13:17:41.909765Z","shell.execute_reply":"2025-09-10T13:40:41.802396Z"}},"outputs":[{"name":"stderr","text":"Evaluate on test set: 100%|██████████| 1057/1057 [22:59<00:00,  1.31s/it]","output_type":"stream"},{"name":"stdout","text":"rouge1: Precision=0.6269, Recall=0.5095, F1=0.5474\nrouge2: Precision=0.2679, Recall=0.2185, F1=0.2342\nrougeL: Precision=0.4113, Recall=0.3331, F1=0.3581\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":30}]}